# Personas
https://github.com/anthropics/anthropic-cookbook
# Prompts
https://docs.anthropic.com/claude/prompt-library
# Attention is all you need (Research paper)
https://github.com/Skumarr53/Attention-is-All-you-Need-PyTorch/blob/master/Attention_is_all_you_need.pdf
# Transformer

# Silicon Valley Documentary

## About the Documentary
"Silicon Valley" explores the rise and influence of the tech hub that has become synonymous with cutting-edge technology and innovation. The documentary chronicles the stories of the region's trailblazers and the breakthroughs that have shaped our digital age.

## Watching the Documentary
The full documentary is available online and can be viewed through the following link: 
[Silicon Valley - American Experience](https://ihavenotv.com/silicon-valley-american-experience)

In his book "The Master Algorithm," Pedro Domingos describes the concept of five "tribes" in machine learning, each with its own fundamental approach to learning from data. These tribes are:

Symbolists: They view learning as the inverse of deduction and take a logical approach to model the world. Their methods are based on inverse deduction to learn the set of rules that produce the given outcomes. A classic example of a symbolist method is decision tree learning.

Connectionists: Inspired by the neural networks in the human brain, they create systems (artificial neural networks) that learn to recognize patterns from large amounts of data. Connectionists aim to simulate neural processes to facilitate learning.

Evolutionaries: Drawing inspiration from the biological process of evolution, they create algorithms that simulate mutation, crossover, and survival of the fittest to evolve solutions to problems. Genetic algorithms are an example of this approach.

Bayesians: They focus on probabilistic reasoning and treat learning as a form of statistical inference. Bayesians use Bayes' Theorem to update the probabilities of hypotheses as more evidence is obtained.

Analogizers: They emphasize the importance of similarity judgments, learning about new instances by comparing them to known instances. The k-nearest neighbors algorithm, which predicts the label of a new instance based on the labels of its closest neighbors in the data space, is a typical example.

